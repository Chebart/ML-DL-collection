{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation function(hard_swish),it's slightly better then ReLU.\n",
    "# We use h-swish at the second half of the model since\n",
    "# the cost of applying nonlinearity decreases as we go\n",
    "# deeper into the network.\n",
    "class H_wsish(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(H_wsish,self).__init__()\n",
    "        self.relu = nn.ReLU6()\n",
    "\n",
    "    def forward(self,x):\n",
    "        return x*self.relu(x+3.0)/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is taken from the original tf repo.\n",
    "# It ensures that all layers have a channel number that is divisible by 8\n",
    "# It can be seen here: https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n",
    "def make_divisible(x, divisor=8, min_value=None):\n",
    "    if min_value is None:\n",
    "        min_value = divisor\n",
    "    new_v = max(min_value, int(x + divisor / 2) // divisor * divisor)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_v < 0.9 * x:\n",
    "        new_v += divisor\n",
    "    return new_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create CNNBlock to simplify implementation\n",
    "class CNNBlock(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,kernel_size,stride,act,bn=True,**kwargs):\n",
    "        super(CNNBlock,self).__init__()\n",
    "        self.bn_true = bn\n",
    "        self.act = act\n",
    "        self.conv = nn.Conv2d(in_channels,out_channels,kernel_size,stride,**kwargs)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.h_swish = H_wsish()\n",
    "        self.relu = nn.ReLU6()\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        if  self.bn_true: x = self.bn(x)\n",
    "        # choose an activation function\n",
    "        if self.act=='HS': x = self.h_swish(x)\n",
    "        else: x = self.relu(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Squeeze-and-excite block.\n",
    "# The size of the SEBlock was relative the size of the convolutional bottleneck,\n",
    "# but we replace them all to fixed to be 1/4 of the number of channels in expansion layer.\n",
    "# It increases the accuracy, at the modest increase of number of\n",
    "# parameters, and no discernible latency cost.\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self,in_channels,divide=4):\n",
    "        super(SEBlock,self).__init__()\n",
    "\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Linear(in_channels, in_channels // divide),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_channels // divide, in_channels),\n",
    "            H_wsish()\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        # batch, channels, height, width\n",
    "        b, c, h, w = x.size()\n",
    "        out = F.avg_pool2d(x, kernel_size=[h, w]).view(b, -1)\n",
    "        out = self.dense(out)\n",
    "        out = out.view(b, c, 1, 1)\n",
    "        return out * x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MobileNet_v2 bottleneck + SEBlock\n",
    "class BottleNeck(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,kernel_size,act,SE,stride,exp):\n",
    "        super(BottleNeck,self).__init__()\n",
    "        self.exp = exp\n",
    "        self.stride = stride\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.SE = SE\n",
    "        self.padding = (self.kernel_size - 1) // 2\n",
    "        self.act = act\n",
    "        \n",
    "        self.pointwise = CNNBlock(in_channels,exp,kernel_size=1,stride=1,act=self.act)\n",
    "        self.depthwise = CNNBlock(exp,exp,self.kernel_size,stride=self.stride,padding=self.padding,\n",
    "                                    groups=exp,act=self.act)\n",
    "        self.SEBlock = SEBlock(exp)\n",
    "        self.conv = CNNBlock(exp,out_channels,kernel_size=1,stride=1,act=self.act)\n",
    "        layers = []\n",
    "\n",
    "        layers.append(nn.Sequential(\n",
    "                self.pointwise,\n",
    "                self.depthwise,\n",
    "                ))\n",
    "\n",
    "        if self.SE:\n",
    "            layers.extend([\n",
    "                self.SEBlock\n",
    "                ])\n",
    "\n",
    "        layers.extend([\n",
    "            self.conv\n",
    "            ])\n",
    "\n",
    "        self.layers = nn.Sequential(*layers)    \n",
    "            \n",
    "    #condition of using of skip connections\n",
    "    def forward(self,x):\n",
    "        if self.stride==1 and self.in_channels==self.out_channels:\n",
    "            x = x + self.layers(x)\n",
    "        else:\n",
    "            x = self.layers(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the end we can drop 3 expensive layers at no loss of accuracy,\n",
    "# it's called efficient last stage.\n",
    "# To see more, read the paper https://arxiv.org/pdf/1905.02244.pdf\n",
    "class MobileNet_v3(nn.Module):\n",
    "    def __init__(self,cnfg,img_channels,num_classes,size):\n",
    "        super(MobileNet_v3,self).__init__()\n",
    "        \n",
    "        model = []\n",
    "        self.out_channels = 16\n",
    "        self.out_channels = make_divisible(self.out_channels*1.0)\n",
    "\n",
    "        if size=='large':\n",
    "            self.conv1 = CNNBlock(img_channels,self.out_channels,kernel_size=3,stride=2,act='HS')\n",
    "            self.conv2 = CNNBlock(make_divisible(160*1.0),960,kernel_size=1,stride=1,act='HS')\n",
    "            self.conv3 = CNNBlock(make_divisible(960*1.0),1280,kernel_size=1,stride=1,bn=False,act='HS')\n",
    "            self.conv4 = nn.Conv2d(make_divisible(1280*1.0),num_classes,kernel_size=1,stride=1)\n",
    "        else:\n",
    "            self.conv1 = CNNBlock(img_channels,self.out_channels,kernel_size=3,stride=2,act='HS')\n",
    "            self.conv2 = CNNBlock(make_divisible(96*1.0),576,kernel_size=1,stride=1,act='HS')\n",
    "            self.conv3 = CNNBlock(make_divisible(576*1.0),1024,kernel_size=1,stride=1,bn=False,act='HS')\n",
    "            self.conv4 = nn.Conv2d(make_divisible(1024*1.0),num_classes,kernel_size=1,stride=1)\n",
    "            \n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.bottlenecks = cnfg\n",
    "\n",
    "        for inp,out,s,ker_size,SE,NL,exp_size in self.bottlenecks:\n",
    "            inp = make_divisible(inp*1.0)\n",
    "            out = make_divisible(out*1.0)\n",
    "            exp_size = make_divisible(exp_size*1.0)\n",
    "            model.append(BottleNeck(inp,out,kernel_size=ker_size,act=NL,SE=SE,stride=s,exp=exp_size))\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.model(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.avg_pool(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = x.view(-1, 1000)\n",
    "        return x \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create MobileNet_v3_large\n",
    "def mobile_net_v3_large(img_channels=3,num_classes=1000):\n",
    "    # t,c,s,ker_size,SE,NL - \n",
    "    # input channels,output channels,stride,kernel size,use SEBlock,type of nonlinearity,expansion\n",
    "    cnfg = [\n",
    "        [16,16,1,3,False,'RE',16],\n",
    "        [16,24,2,3,False,'RE',64],\n",
    "        [24,24,1,3,False,'RE',72],\n",
    "        [24,40,2,5,True,'RE',72],\n",
    "        [40,40,1,5,True,'RE',120],\n",
    "        [40,40,1,5,True,'RE',120],\n",
    "        [40,80,2,3,False,'HS',240],\n",
    "        [80,80,1,3,False,'HS',200],\n",
    "        [80,80,1,3,False,'HS',184],\n",
    "        [80,80,1,3,False,'HS',184],\n",
    "        [80,112,1,3,True,'HS',480],\n",
    "        [112,112,1,3,True,'HS',672],\n",
    "        [112,160,2,5,True,'HS',672],\n",
    "        [160,160,1,5,True,'HS',960],\n",
    "        [160,160,1,5,True,'HS',960]]\n",
    "\n",
    "    return MobileNet_v3(cnfg,img_channels,num_classes,'large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create MobileNet_v3_small\n",
    "def mobile_net_v3_small(img_channels=3,num_classes=1000):\n",
    "    # t,c,s,ker_size,SE,NL - \n",
    "    # input channels,output channels,stride,kernel size,use SEBlock,type of nonlinearity,expansion    \n",
    "    cnfg = [\n",
    "        [16,16,2,3,True,'RE',16],\n",
    "        [16,24,2,3,False,'RE',72],\n",
    "        [24,24,1,3,False,'RE',88],\n",
    "        [24,40,2,5,True,'HS',96],\n",
    "        [40,40,1,5,True,'HS',240],\n",
    "        [40,40,1,5,True,'HS',240],\n",
    "        [40,48,1,5,True,'HS',120],\n",
    "        [48,48,1,5,True,'HS',144],\n",
    "        [48,96,2,5,True,'HS',288],\n",
    "        [96,96,1,5,True,'HS',576],\n",
    "        [96,96,1,5,True,'HS',576]]\n",
    "\n",
    "    return MobileNet_v3(cnfg,img_channels,num_classes,'small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the net architecture\n",
    "def test():\n",
    "    net = mobile_net_v3_small()\n",
    "    x = torch.rand(2,3,224,224)\n",
    "    y = net(x)\n",
    "    print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1000])\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a14e8f5ab3b28230cbcab04c68e03313c17b063e7274313dff80aca90639841b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
